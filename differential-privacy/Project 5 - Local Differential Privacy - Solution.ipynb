{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1: Generate Parallel Databases\n",
    "\n",
    "Key to the definition of differenital privacy is the ability to ask the question \"When querying a database, if I removed someone from the database, would the output of the query be any different?\". Thus, in order to check this, we must construct what we term \"parallel databases\" which are simply databases with one entry removed. \n",
    "\n",
    "In this first project, I want you to create a list of every parallel database to the one currently contained in the \"db\" variable. Then, I want you to create a function which both:\n",
    "\n",
    "- creates the initial database (db)\n",
    "- creates all parallel databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# the number of entries in our database\n",
    "num_entries = 5000\n",
    "db = torch.rand(num_entries) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1,  ..., 1, 1, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_parallel_db(db, remove_index):\n",
    "    \"\"\"Returns a parallel database by removing\n",
    "    one sample from a given index\n",
    "    \n",
    "    Args:\n",
    "        db (tensor): The original database.\n",
    "        remove_index (int): specifies which sample to remove.\n",
    "\n",
    "    Returns:\n",
    "        tensor: a pararllel database.\n",
    "    \"\"\"\n",
    "    # TODO: Remove one sample from the database using the remove_index\n",
    "    \n",
    "    parallel_db = torch.cat((db[0:remove_index], \n",
    "                             db[remove_index+1:]))\n",
    "    return parallel_db\n",
    "\n",
    "get_parallel_db(db, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 0, 1,  ..., 1, 1, 1], dtype=torch.uint8),\n",
       " tensor([1, 0, 1,  ..., 1, 1, 1], dtype=torch.uint8),\n",
       " tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.uint8)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_parallel_dbs(db):\n",
    "    \"\"\"Returns a list of all the possible parallel \n",
    "    databases of a given database\n",
    "    \n",
    "    Args:\n",
    "        db (tensor): The original database.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of pararllel databases.\n",
    "    \"\"\"\n",
    "    parallel_dbs = list()\n",
    "    \n",
    "    # TODO: Create a list of parallel databases for every index\n",
    "    for i in range(len(db)):\n",
    "        pdb = get_parallel_db(db, i)\n",
    "        parallel_dbs.append(pdb)\n",
    "        \n",
    "    return parallel_dbs\n",
    "\n",
    "pdbs = get_parallel_dbs(db)\n",
    "pdbs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_db_and_parallels(num_entries):\n",
    "    \"\"\"Initializes a databes and creates a list of \n",
    "    all the possible parallel databases of itself\n",
    "    \n",
    "    Args:\n",
    "        num_entries (int): length of the original database.\n",
    "\n",
    "    Returns:\n",
    "        db (tensor): the original database.\n",
    "        pdbs (list): a list of pararllel databases.\n",
    "    \"\"\"\n",
    "    # TODO: Initialize a database and all its parallel databases\n",
    "    \n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    pdbs = get_parallel_dbs(db)\n",
    "    \n",
    "    return db, pdbs\n",
    "\n",
    "db, pdbs = create_db_and_parallels(20)\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Evaluating the Privacy of a Function\n",
    "\n",
    "In the last section, we measured the difference between each parallel db's query result and the query result for the entire database and then calculated the max value (which was 1). This value is called \"sensitivity\", and it corresponds to the function we chose for the query. Namely, the \"sum\" query will always have a sensitivity of exactly 1. However, we can also calculate sensitivity for other functions as well.\n",
    "\n",
    "Let's try to calculate sensitivity for the \"mean\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    \"\"\"Queries the database by computing a mean\"\"\"\n",
    "    return db.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(query, n_entries=1000):\n",
    "    \"\"\"Computes the sensitivity of a given query\n",
    "    for a particular database\n",
    "    \n",
    "    Args:\n",
    "        query (fn): a function that queries the database.\n",
    "        n_entries (int): size of the database.\n",
    "\n",
    "    Returns:\n",
    "        tensor: the resulting sensitivity.\n",
    "    \"\"\"\n",
    "    # TODO: Create a custon database and its parallel databases\n",
    "    db, pdbs = create_db_and_parallels(n_entries)\n",
    "    \n",
    "    # TODO: Query the full database\n",
    "    full_db_result = query(db)\n",
    "    \n",
    "    # TODO: Loop through the parallel databases and compute the maximum sensitivity\n",
    "    sensitivity = 0\n",
    "    for pdb in pdbs:\n",
    "        pdb_result = query(pdb)\n",
    "\n",
    "        db_distance = torch.abs(pdb_result - full_db_result)\n",
    "\n",
    "        if(db_distance > sensitivity):\n",
    "            sensitivity = db_distance\n",
    "            \n",
    "    return sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Calculate L1 Sensitivity For Threshold\n",
    "\n",
    "In this first project, I want you to calculate the sensitivty for the \"threshold\" function. \n",
    "\n",
    "- First compute the sum over the database (i.e. sum(db)) and return whether that sum is greater than a certain threshold.\n",
    "- Then, I want you to create databases of size 10 and threshold of 5 and calculate the sensitivity of the function. \n",
    "- Finally, re-initialize the database 10 times and calculate the sensitivity each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db, threshold=5):\n",
    "    \"\"\"Computes the sum over a database and returns \n",
    "    whether that sum is greater than a certain threshold\n",
    "    \n",
    "    Args:\n",
    "        db (tensor): randomly generated database.\n",
    "        threshold (int): threshold to compare with query result.\n",
    "\n",
    "    Returns:\n",
    "        tensor: output of the query with threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Compute the sum over the database and check \n",
    "    # if it is graterer than the given threshold.\n",
    "    \n",
    "    return (db.sum() > threshold).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: create a database of size 10 and threshold of 5 and calculate the sensitivity of the function.\n",
    "sensitivity(query, n_entries=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "tensor(1.)\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# TODO: re-initialize the database 10 times and calculate the sensitivity each time.\n",
    "for i in range(10):\n",
    "    sens_f = sensitivity(query, n_entries=10)\n",
    "    print(sens_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Perform a Differencing Attack on Row 10\n",
    "\n",
    "In this project, I want you to construct a database and then demonstrate how you can use two different sum queries to explose the value of the person represented by row 10 in the database (note, you'll need to use a database with at least 10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Construct a database with at least 10 rows\n",
    "db, _ = create_db_and_parallels(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get a parallel db by removing the 10th row\n",
    "pdb = get_parallel_db(db, remove_index=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: differencing attack using sum query\n",
    "sum(db) - sum(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0043)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: differencing attack using mean query\n",
    "(sum(db).float() / len(db)) - (sum(pdb).float() / len(pdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: differencing attack using threshold\n",
    "(sum(db).float() > 49) - (sum(pdb).float()  > 49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Local Differential Privacy\n",
    "\n",
    "As you can see, the basic sum query is not differentially private at all! In truth, differential privacy always requires a form of randomness added to the query. Let me show you what I mean.\n",
    "\n",
    "### Randomized Response (Local Differential Privacy)\n",
    "\n",
    "Let's say I have a group of people I wish to survey about a very taboo behavior which I think they will lie about (say, I want to know if they have ever committed a certain kind of crime). I'm not a policeman, I'm just trying to collect statistics to understand the higher level trend in society. So, how do we do this? One technique is to add randomness to each person's response by giving each person the following instructions (assuming I'm asking a simple yes/no question):\n",
    "\n",
    "- Flip a coin 2 times.\n",
    "- If the first coin flip is heads, answer honestly\n",
    "- If the first coin flip is tails, answer according to the second coin flip (heads for yes, tails for no)!\n",
    "\n",
    "Thus, each person is now protected with \"plausible deniability\". If they answer \"Yes\" to the question \"have you committed X crime?\", then it might becasue they actually did, or it might be becasue they are answering according to a random coin flip. Each person has a high degree of protection. Furthermore, we can recover the underlying statistics with some accuracy, as the \"true statistics\" are simply averaged with a 50% probability. Thus, if we collect a bunch of samples and it turns out that 60% of people answer yes, then we know that the TRUE distribution is actually centered around 70%, because 70% averaged wtih 50% (a coin flip) is 60% which is the result we obtained. \n",
    "\n",
    "However, it should be noted that, especially when we only have a few samples, the this comes at the cost of accuracy. This tradeoff exists across all of Differential Privacy. The greater the privacy protection (plausible deniability) the less accurate the results. \n",
    "\n",
    "Let's implement this local DP for our database before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db):\n",
    "    \"\"\"Adds random noise to the dataset using \n",
    "    local differential privacy and performs a\n",
    "    query into the augmented database\n",
    "    \n",
    "    Args:\n",
    "        db (tensor): randomly generated database.\n",
    "\n",
    "    Returns:\n",
    "        db_result (tensor): output of the query on the augmented database. \n",
    "        true_result (tensor): output of the query on the true database. \n",
    "    \n",
    "    \"\"\"\n",
    "    # TODO: Perform a mean query on the original database\n",
    "    true_result = torch.mean(db.float())\n",
    "    \n",
    "    # TODO: Simulate the coin flips (Tip: use the torch.rand method)\n",
    "    first_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "    second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "\n",
    "    # TODO: Add the noise to the database using the simulated coin flips\n",
    "    augmented_database = db.float() * first_coin_flip + (1 - first_coin_flip) * second_coin_flip\n",
    "    \n",
    "    # TODO: Perform a mean query on the augmented database\n",
    "    # NOTE: You should remove the noise after computing the query\n",
    "    db_result = torch.mean(augmented_database.float()) * 2 - 0.5\n",
    "    \n",
    "    return db_result, true_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise:tensor(0.1000)\n",
      "Without Noise:tensor(0.3000)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(10)\n",
    "private_result, true_result = query(db)\n",
    "print(\"With Noise:\" + str(private_result))\n",
    "print(\"Without Noise:\" + str(true_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise:tensor(0.5200)\n",
      "Without Noise:tensor(0.4900)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(100)\n",
    "private_result, true_result = query(db)\n",
    "print(\"With Noise:\" + str(private_result))\n",
    "print(\"Without Noise:\" + str(true_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise:tensor(0.5100)\n",
      "Without Noise:tensor(0.4930)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(1000)\n",
    "private_result, true_result = query(db)\n",
    "print(\"With Noise:\" + str(private_result))\n",
    "print(\"Without Noise:\" + str(true_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Noise:tensor(0.5076)\n",
      "Without Noise:tensor(0.5007)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(10000)\n",
    "private_result, true_result = query(db)\n",
    "print(\"With Noise:\" + str(private_result))\n",
    "print(\"Without Noise:\" + str(true_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
